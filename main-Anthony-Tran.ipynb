{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e826565-3d39-48be-af8c-a9a876811a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install openai\n",
    "# !pip install -U langchain-community\n",
    "# !pip install tiktoken\n",
    "# !pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7e4c83e-ff77-4b23-8c59-c0d50084e820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ZIP extracted to: python_docs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "\n",
    "zip_path = \"python-3.13-docs-text.zip\"\n",
    "extract_dir = \"python_docs\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "\n",
    "print(\"‚úÖ ZIP extracted to:\", extract_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0873b25-ced2-43ad-8cb0-0f403b1c637e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Loaded 507 text documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "documents = []\n",
    "\n",
    "for root, _, files in os.walk(\"python_docs\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            with open(os.path.join(root, file), \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "                documents.append(Document(page_content=text, metadata={\"source\": file}))\n",
    "\n",
    "print(f\"üìÑ Loaded {len(documents)} text documents.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21745697-0045-444f-86bd-f32c2a20d0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÇÔ∏è Total text chunks: 15919\n"
     ]
    }
   ],
   "source": [
    "#split documents into chunks\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "split_docs = splitter.split_documents(documents)\n",
    "\n",
    "print(f\"‚úÇÔ∏è Total text chunks: {len(split_docs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e7abb06-b587-47e2-ac20-c44415478a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üîê Enter your OpenAI API key:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "# Ask for API key safely\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"üîê Enter your OpenAI API key: \")\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93417437-1fa4-48c3-b19b-fee892600b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trahu\\AppData\\Local\\Temp\\ipykernel_14676\\2928076918.py:4: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b316a394-aacc-4ce8-a15b-fa386c683c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trahu\\AppData\\Local\\Temp\\ipykernel_14676\\682399099.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", \n",
    "    return_messages=True,\n",
    "    output_key=\"answer\"  # ‚úÖ tell it to store only the answer\n",
    ")\n",
    "\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    output_key=\"answer\"  # ‚úÖ same fix here\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddbe998-f7e4-4078-9185-be9179948a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Ask me anything about Python docs! Type 'exit' to quit.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üßë You:  hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trahu\\AppData\\Local\\Temp\\ipykernel_14676\\3500014405.py:9: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = conversation_chain({\"question\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Answer:\n",
      "Hello! How can I assist you today?\n",
      "\n",
      "üìö Sources:\n",
      " - itertools.txt\n",
      " - 3.11.txt\n",
      " - xml.txt\n",
      " - buffer.txt\n",
      "\n",
      "---\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üßë You:  can you write me java script?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Answer:\n",
      "I don't know how to write JavaScript.\n",
      "\n",
      "üìö Sources:\n",
      " - appetite.txt\n",
      " - appetite.txt\n",
      " - appetite.txt\n",
      " - turtle.txt\n",
      "\n",
      "---\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üßë You:  what about any other language\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Answer:\n",
      "Based on the context provided, Python is highlighted as a suitable language for automating tasks, developing GUI applications, and creating games. The context does not mention any other specific languages for writing programs.\n",
      "\n",
      "üìö Sources:\n",
      " - appetite.txt\n",
      " - appetite.txt\n",
      " - codecs.txt\n",
      " - codecs.txt\n",
      "\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßë You:  do it for java\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Answer:\n",
      "I don't know.\n",
      "\n",
      "üìö Sources:\n",
      " - controlflow.txt\n",
      " - 3.10.txt\n",
      " - programming.txt\n",
      " - compound_stmts.txt\n",
      "\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßë You:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëã Goodbye!\n"
     ]
    }
   ],
   "source": [
    "print(\"ü§ñ Ask me anything about Python docs! Type 'exit' to quit.\\n\")\n",
    "\n",
    "while True:\n",
    "    query = input(\"üßë You: \")\n",
    "    if query.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "        print(\"üëã Goodbye!\")\n",
    "        break\n",
    "\n",
    "    result = conversation_chain({\"question\": query})\n",
    "\n",
    "    print(\"\\nü§ñ Answer:\\n\" + result[\"answer\"])\n",
    "\n",
    "    print(\"\\nüìö Sources:\")\n",
    "    for doc in result[\"source_documents\"]:\n",
    "        print(\" -\", doc.metadata[\"source\"])\n",
    "    \n",
    "    print(\"\\n---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aedd18-d41b-4e28-baa1-6e135686660d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
